{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MN Geospatial Commons API\n",
    "\n",
    "This script searches the MN Geospatial Commons using tags and returns search results. It then extracts one specified dataset from the search results or all of the datasets, and unzips the extracted datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "packages = requests.get(\"https://gisdata.mn.gov/api/3/action/package_list\", verify=False)\n",
    "tag_list = requests.get(\"https://gisdata.mn.gov/api/3/action/tag_list\", verify=False)\n",
    "group_list = requests.get(\"https://gisdata.mn.gov/api/3/action/group_list\", verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All datasets available\n",
    "packages_dict = packages.json()\n",
    "assert packages_dict['success'] is True \n",
    "\n",
    "# All tags availabile\n",
    "tag_dict = tag_list.json()\n",
    "assert tag_dict['success'] is True \n",
    "\n",
    "# All categories available\n",
    "group_dict = group_list.json()\n",
    "assert group_dict['success'] is True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = packages_dict['result']\n",
    "tags = tag_dict['result']\n",
    "groups = group_dict['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: ['100k index', '103e', '15 minute', '1994', '1-meter orthophoto', '1 water supply planning working groups', '2000 census', '2002', '2010', '2010 census']\n",
      "\n",
      "groups: ['biota', 'boundaries', 'climatology', 'economy', 'elevation', 'environment', 'farming', 'geoscientific', 'health', 'imagery-basemaps', 'inland-waters', 'intelligence-military', 'location', 'planning-cadastre', 'society', 'structure', 'transportation', 'utilities-communication']\n"
     ]
    }
   ],
   "source": [
    "# adjust index to see tags more or less tags\n",
    "print(f\"tags: {tags[:10]}\")\n",
    "print(f\"\\ngroups: {groups}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to view all datasets possible\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying and extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'gisdata.mn.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    }
   ],
   "source": [
    "# use '+' to seperate multiple tags in query i.e 2020+farming\n",
    "query = \"2030\"\n",
    "\n",
    "search_response = requests.get(f\"https://gisdata.mn.gov/api/3/action/package_search?q={query}\", verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = search_response.json()\n",
    "assert search['success'] is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search result count: 9\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search result count: {search['result']['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get url for first result only\n",
    "data = search['result']['results'][0]['resources'][1]['url']\n",
    "data_id = search['result']['results'][0]['resources'][1]['id']\n",
    "out_name = f\"{data_id}.zip\"\n",
    "\n",
    "\n",
    "# Write file to specified output type. Out path is same as this jupyter notebook.\n",
    "r = requests.get(data)\n",
    "assert r.status_code is 200\n",
    " \n",
    "with open(out_name, \"wb\") as file:\n",
    "    file.write(r.content)\n",
    "    \n",
    "with ZipFile(out_name, \"r\") as zipped:\n",
    "    print(zipped.namelist())\n",
    "    zipped.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the urls for ALL the search results. Can specify format type. \n",
    "# Could you use this to extract all data from each url?\n",
    "search_urls = []\n",
    "ids = []\n",
    "for i in search['result']['results']:\n",
    "    for x in i['resources']:\n",
    "        if x['format'] == 'SHP': # return only specified shp file \n",
    "            search_urls.append(x['url'])\n",
    "            ids.append(x['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from all the URLS and named with their ID\n",
    "for i in range(len(search_urls)):\n",
    "    r = requests.get(search_urls[i])\n",
    "    assert r.status_code is 200\n",
    "    \n",
    "    with open(f\"{ids[i]}.zip\", \"wb\") as file:\n",
    "        file.write(r.content)\n",
    "    \n",
    "    with ZipFile(f\"{ids[i]}.zip\", \"r\") as zipped:\n",
    "        print(zipped.namelist())\n",
    "        zipped.extractall()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
